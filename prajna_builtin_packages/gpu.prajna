use ::cuda;

func Init(){
    cuda::cuInit(0i32);
}

func SetDevice(id: i64){
    cuda::cudaSetDevice(id).ToString();
}

func MaxThreadPerBlock(device: i64)->i64{
    var count: i32;
    cuda::cuDeviceGetAttribute(&count, 1i32, device.Cast<i32>());
    return count.Cast<i64>();
}

func MultiProcessorsCount(device: i64)->i64{
    var count: i32;
    cuda::cuDeviceGetAttribute(&count, 16i32, device.Cast<i32>());
    return count.Cast<i64>();
}

func LaunchKernel(kernel_function_pointer: __ptr<i8>, GridShape: Array<i64, 3>, BlockShape: Array<i64, 3>, kernel_params: __ptr<__ptr<i8>>)->i64{
    var re = cuda::cuLaunchKernel(kernel_function_pointer, GridShape[0].Cast<u32>(), GridShape[1].Cast<u32>(),
    GridShape[2].Cast<u32>(), BlockShape[0].Cast<u32>(), BlockShape[1].Cast<u32>(), BlockShape[2].Cast<u32>(), 0u32, __cast<i64, __ptr<i8>>(0), kernel_params, __cast<i64, __ptr<__ptr<i8> > >(0));
    return re.Cast<i64>();
}

func LaunchKernelForDim1(kernel_function_pointer: __ptr<i8>, paramters: __ptr<__ptr<i8>>){

}

template <Type, Dim>
struct Tensor {
    data : __ptr<Type>;
    layout: Layout<Dim>;
}

template <Type, Dim>
interface AtProperty {
    func Get(idx: Array<i64, Dim>)->Type;
    func Set(idx: Array<i64, Dim>, value: Type);
}

template <Type, Dim>
implement AtProperty<Type, Dim> for Tensor<Type, Dim>{
    @inline
    func Get(idx: Array<i64, Dim>)->Type{
        var offset = this.layout.ArrayIndexToLinearIndex(idx);
        return this.data[offset];
    }
    @inline
    func Set(idx: Array<i64, Dim>, value: Type){
        var offset = this.layout.ArrayIndexToLinearIndex(idx);
        this.data[offset] = value;
    }
}

template <Type, Dim>
implement operator::ArrayIndex<Type, Dim> for Tensor<Type, Dim> {
    @inline
    func Get(index: Array<i64, Dim>)->Type{
        return this.At(index);
    }

    @inline
    func Set(index: Array<i64, Dim>, value: Type){
        this.At(index) = value;
    }
}

template <Type, Dim>
implement Tensor<Type, Dim> {
    @static
    func Create(shape :Array<i64, Dim>)->Tensor<Type, Dim>{
        var self: Tensor<Type, Dim>;
        self.layout = Layout<Dim>::Create(shape);

        var bytes = self.layout.Length() * __sizeof<Type>();
        cuda::cuMemAlloc(__bit_cast<__ptr<__ptr<Type>> ,__ptr<__ptr<i8> > >(&self.data), bytes);
        bindings::RegisterReferenceCount(__bit_cast<__ptr<Type> ,__ptr<undef>>(self.data));
        bindings::IncrementReferenceCount(__bit_cast<__ptr<Type> ,__ptr<undef>>(self.data));

        return self;
    }

    @inline
    func Shape()->Array<i64, Dim> {
        return this.layout.shape;
    }


    func ToHost()->::Tensor<Type, Dim>{
        var host_tensor = ::Tensor<Type, Dim>::Create(this.layout.shape);
        var size = 1;
        for i in 0 to Dim {
            size = size * this.layout.shape[i];
        }
        var re =  cuda::cudaMemcpy(__bit_cast<__ptr<Type> ,__ptr<i8>>(host_tensor.data.raw_ptr), __bit_cast<__ptr<Type>, __ptr<i8>>(this.data), size * __sizeof<Type>(), 2i32);
        return host_tensor;
    }
}

template <Type, Dim>
implement ::Tensor<Type, Dim> {
    func ToGpu()->Tensor<Type, Dim>{
        var cuda_tensor = Tensor<Type, Dim>::Create(this.layout.shape);
        var size = 1;
        for i in 0 to Dim {
            size = size * this.layout.shape[i];
        }
        var re = cuda::cudaMemcpy(__bit_cast<__ptr<Type> ,__ptr<i8>>(cuda_tensor.data), __bit_cast<__ptr<Type>, __ptr<i8>>(this.data.raw_ptr), size * __sizeof<Type>(), 1i32);
        return cuda_tensor;
    }
}

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.x")
func __thread_idx_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.y")
func __thread_idx_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.tid.z")
func __thread_idx_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.x")
func __block_shape_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.y")
func __block_shape_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ntid.z")
func __block_shape_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.x")
func __block_idx_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.y")
func __block_idx_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.ctaid.z")
func __block_idx_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.x")
func __grid_shape_x()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.y")
func __grid_shape_y()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.nctaid.z")
func __grid_shape_z()->u32;

@target("nvptx")
@intrinsic("llvm.nvvm.read.ptx.sreg.warpsize")
func __warp_size()->u32;

@inline
@target("nvptx")
func ThreadIndex()->Array<i64, 3> {
    return [__thread_idx_x().Cast<i64>(), __thread_idx_y().Cast<i64>(), __thread_idx_z().Cast<i64>()];
}

@inline
@target("nvptx")
func BlockShape()->Array<i64, 3> {
    return [__block_shape_x().Cast<i64>(), __block_shape_y().Cast<i64>(), __block_shape_z().Cast<i64>()];
}

@inline
@target("nvptx")
func BlockIndex()->Array<i64, 3> {
    return [__block_idx_x().Cast<i64>(), __block_idx_y().Cast<i64>(), __block_idx_z().Cast<i64>()];
}

@inline
@target("nvptx")
func GridShape()->Array<i64, 3> {
    return [__grid_shape_x().Cast<i64>(), __grid_shape_y().Cast<i64>(), __grid_shape_z().Cast<i64>()];
}
